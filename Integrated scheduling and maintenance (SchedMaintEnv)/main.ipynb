{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from SchedMaint_env import GASU\n",
    "from GASU_optimizer import optimize_GASU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode Length: T\n",
    "T = 31\n",
    "state_horizon = 30\n",
    "action_horizon = 1\n",
    "simulation_days = T + state_horizon - action_horizon       # Total simulation days = 60\n",
    "env_id = 'GASU-v0'\n",
    "env = GASU(env_id, config_path=\"gasu_config.json\")\n",
    "\n",
    "# Preprocessing\n",
    "# Step 1: Rendering essential information from environment\n",
    "compressors = env.compressor_info()       # Provides the infromation compressors and its initial state in dict format\n",
    "external_purchase_price = env.get_external_purchase_price()    # Provides the dict of external purchase price\n",
    "external_purchase_capacity = env.get_external_purchase_capacity()    # Provides the dict of external purchase capacity\n",
    "\n",
    "# Step 2: Initializing the optimizer by feeding the essential information from environment\n",
    "optimizer = optimize_GASU(state_horizon, action_horizon, compressors)\n",
    "optimizer._update_external_purchase_price(external_purchase_price)         # __Update the external purchase price in optimizer__\n",
    "optimizer._update_external_purchase_capacity(external_purchase_capacity)   # __Update the external purchase capacity in optimizer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation for 31 days (with optimal action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Episode Reward: 1221.8517861219732\n",
      "Final Episode Reward: -1221.3104362487793\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "flatt_state = env._get_state('flatt')  # mode = 'flatt'\n",
    "opt_episode_reward = 0\n",
    "simulation_episode_reward = 0\n",
    "terminated = torch.tensor(False)\n",
    "\n",
    "while terminated.item() is False:\n",
    "\n",
    "    optimizer.update_state(flatt_state)\n",
    "    objective_value = optimizer.solve()\n",
    "    opt_cost = optimizer.action_horizon_cost()\n",
    "    opt_action = optimizer._fetch_optimal_action_for_action_horizon()\n",
    "    # feed action to environment, # tensor output\n",
    "    flatt_state_tensor, reward, terminated, truncated, info = env.step(opt_action)\n",
    "    flatt_state = env._get_state('flatt')\n",
    "    opt_episode_reward += opt_cost\n",
    "    simulation_episode_reward += reward.item()\n",
    "    \n",
    "print(f\"Optimal Episode Reward: {opt_episode_reward}\")\n",
    "print(f\"Final Episode Reward: {simulation_episode_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Episode cost per (δ1,δ2,δ3) ---\n",
      "(0, 0, 0): 1221.85\n",
      "(0, 0, 1): 1221.86\n",
      "(0, 0, 2): 1229.37\n",
      "(0, 1, 0): 1221.23\n",
      "(0, 1, 1): 1221.24\n",
      "(0, 1, 2): 1228.75\n",
      "(0, 2, 0): 1221.79\n",
      "(0, 2, 1): 1221.80\n",
      "(0, 2, 2): 1229.31\n",
      "(1, 0, 0): 1224.63\n",
      "(1, 0, 1): 1224.64\n",
      "(1, 0, 2): 1224.65\n",
      "(1, 1, 0): 1224.00\n",
      "(1, 1, 1): 1224.01\n",
      "(1, 1, 2): 1224.02\n",
      "(1, 2, 0): 1224.56\n",
      "(1, 2, 1): 1224.57\n",
      "(1, 2, 2): 1224.58\n",
      "(2, 0, 0): 1232.55\n",
      "(2, 0, 1): 1232.56\n",
      "(2, 0, 2): 1232.57\n",
      "(2, 1, 0): 1231.92\n",
      "(2, 1, 1): 1231.93\n",
      "(2, 1, 2): 1231.94\n",
      "(2, 2, 0): 1232.48\n",
      "(2, 2, 1): 1232.49\n",
      "(2, 2, 2): 1232.50\n",
      "\n",
      "Average optimal episode cost across 27 scenarios: 1226.96\n"
     ]
    }
   ],
   "source": [
    "import json, copy, os, uuid\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from SchedMaint_env import GASU\n",
    "from GASU_optimizer import optimize_GASU\n",
    "\n",
    "def write_scenario_json(nominal_cfg, deltas):\n",
    "    cfg = copy.deepcopy(nominal_cfg)\n",
    "    for comp, d in zip(cfg[\"compressors\"], deltas):\n",
    "        comp[\"mttf\"] = max(comp[\"mttf\"] - d, 1)\n",
    "\n",
    "    fname = f\"gasu_tmp_{uuid.uuid4().hex}.json\"\n",
    "    with open(fname, \"w\") as f:\n",
    "        json.dump(cfg, f, indent=4)\n",
    "    return fname\n",
    "\n",
    "\n",
    "def run_episode(env, optimizer):\n",
    "    env.reset()\n",
    "    flatt_state = env._get_state(\"flatt\")\n",
    "    terminated  = torch.tensor(False)\n",
    "    ep_cost     = 0.0\n",
    "\n",
    "    while not terminated.item():\n",
    "        optimizer.update_state(flatt_state)\n",
    "        optimizer.solve()\n",
    "        ep_cost += optimizer.action_horizon_cost()\n",
    "\n",
    "        act = optimizer._fetch_optimal_action_for_action_horizon()\n",
    "        _, _, terminated, _, _ = env.step(act)\n",
    "        flatt_state = env._get_state(\"flatt\")\n",
    "\n",
    "    return ep_cost\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ---------------- nominal config -----------------\n",
    "    with open(\"gasu_config.json\", \"r\") as f:\n",
    "        nominal_cfg = json.load(f)\n",
    "\n",
    "    T               = 31\n",
    "    state_horizon   = 30\n",
    "    action_horizon  = 1\n",
    "    env_id          = \"GASU-v0\"\n",
    "\n",
    "    scenario_costs = {}           # {(δ1,δ2,δ3): cost}\n",
    "\n",
    "    for deltas in product([0, 1, 2], repeat=3):\n",
    "        cfg_path = write_scenario_json(nominal_cfg, deltas)\n",
    "\n",
    "        # ---------- env & optimiser for this scenario ----------\n",
    "        env = GASU(env_id, config_path=cfg_path)\n",
    "        compressors               = env.compressor_info()\n",
    "        ext_price                 = env.get_external_purchase_price()\n",
    "        ext_capacity              = env.get_external_purchase_capacity()\n",
    "\n",
    "        optimizer = optimize_GASU(state_horizon, action_horizon, compressors)\n",
    "        optimizer._update_external_purchase_price(ext_price)\n",
    "        optimizer._update_external_purchase_capacity(ext_capacity)\n",
    "\n",
    "        # ---------- roll out episode ----------\n",
    "        episode_cost = run_episode(env, optimizer)\n",
    "        scenario_costs[deltas] = episode_cost\n",
    "\n",
    "        # optional: clean up the temporary file\n",
    "        os.remove(cfg_path)\n",
    "\n",
    "    avg_cost = np.mean(list(scenario_costs.values()))\n",
    "\n",
    "    print(\"\\n--- Episode cost per (δ1,δ2,δ3) ---\")\n",
    "    for k, v in scenario_costs.items():\n",
    "        print(f\"{k}: {v:.2f}\")\n",
    "\n",
    "    print(f\"\\nAverage optimal episode cost across 27 scenarios: {avg_cost:.2f}\")\n",
    "\n",
    "# average cost around 27 scenarios: 1226.96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
