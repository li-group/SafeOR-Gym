{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311368a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_ASU_env import ASUEnv\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16275e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of last observation: 483\n",
      "Episode Terminated\n",
      "number of actions taken: 168\n"
     ]
    }
   ],
   "source": [
    "# base_dir   = Path(__file__).resolve().parent\n",
    "base_dir = Path().resolve()\n",
    "config_fp  = base_dir / \"asuenv_config.json\"\n",
    "if not config_fp.is_file():\n",
    "    raise FileNotFoundError(f\"Couldnâ€™t find config.json at {config_fp}\")\n",
    "\n",
    "env_id = 'ASU1'\n",
    "env = ASUEnv('ASU1', config_path = config_fp)\n",
    "\n",
    "obs, info = env.reset()\n",
    "# print(f\"start of day{1}\", obs.shape[0])\n",
    "\n",
    "terminated = False\n",
    "i = 1\n",
    "num_action = 0\n",
    "state_dict = {}\n",
    "\n",
    "while not terminated:\n",
    "    # Step 1: Receive the observation\n",
    "    # print(f\"start of hour- {i}\", obs.shape[0])\n",
    "    state_dict[i] = {}\n",
    "    obs_dict = env._get_state(mode='dict')\n",
    "    state_dict[i] = deepcopy(obs_dict)\n",
    "    \n",
    "    # Step 2: Choose an action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step 3: Take a step in the environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    num_action += 1\n",
    "    i += 1\n",
    "    if terminated:\n",
    "        obs_dict = env._get_state(mode='dict')\n",
    "        state_dict[i] = obs_dict\n",
    "        print(f\"shape of last observation: {obs.shape[0]}\")\n",
    "        print(\"Episode Terminated\")\n",
    "        print(f\"number of actions taken: {num_action}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ca3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code to read files\n",
    "# with open(\"asuenv_config.json\", \"r\") as f:\n",
    "#     config_data = json.load(f)\n",
    "\n",
    "# # Extract back the original dictionaries\n",
    "# dict_price = config_data[\"price\"]\n",
    "# dict_demand = config_data[\"demand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "391545d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_price, dict_demand = env._initialize_simulation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d0d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24598.826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict[1]['demand'][0][23]\n",
    "state_dict[2]['demand'][0][22]\n",
    "state_dict[3]['demand'][0][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c3f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ASU_env import ASUEnv\n",
    "from ASU_opt_model import optimize_ASU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be6cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actions taken: 168\n",
      "Simulation complete for total of 8 days\n"
     ]
    }
   ],
   "source": [
    "lookahead = 4\n",
    "# env_id = 'ASU1'\n",
    "# env = ASUEnv('ASU1')\n",
    "env_id = 'ASU1'\n",
    "env = ASUEnv('ASU1', config_path = config_fp)\n",
    "\n",
    "# get lookahead value from the environment to feed into the optimizer\n",
    "asu_optimizer = optimize_ASU('ASU1', lookahead)\n",
    "\n",
    "env.reset()\n",
    "current_day = 1\n",
    "optimization_day1_cost = {}\n",
    "opt_lambda = {}\n",
    "opt_reward = {}\n",
    "num_action = 0\n",
    "\n",
    "terminated = False\n",
    "while not terminated:\n",
    "\n",
    "    # state = env.render()\n",
    "    state = env._get_state(mode='dict')\n",
    "    asu_optimizer.update_state(state)\n",
    "    \n",
    "    # Solve the optimization model\n",
    "    objective = asu_optimizer.solve()\n",
    "    day1_cost = asu_optimizer.day1_cost()\n",
    "    optimization_day1_cost[current_day] = day1_cost  \n",
    "    \n",
    "    opt_day_lambda = asu_optimizer.extract_optimal_lambda()\n",
    "    # fetch optimal hourly lambda values for the current day\n",
    "    opt_lambda[current_day] = opt_day_lambda\n",
    "    # based on opt_day_lambda, calculate the reward: opt_reward[current_day]\n",
    "    \n",
    "    day_reward = 0.0\n",
    "    for hour in range(1, 25):\n",
    "        # Retrieve the lambda values for this hour (assume keys in subdict are sorted correctly, e.g., 1, 2, ...).\n",
    "        hourly_lambda = opt_day_lambda[hour]\n",
    "        # Convert the lambda dict to a NumPy array. # For instance, if your extreme points indices are [1,2,...,n], sort the keys and build the array.\n",
    "        lambda_array = np.array([hourly_lambda[k] for k in sorted(hourly_lambda.keys())], dtype=np.float32)\n",
    "        # opt_action = {'lambda': lambda_array}\n",
    "        opt_action = lambda_array\n",
    "        \n",
    "        # Take a step in the environment using this optimal action.\n",
    "        # state, reward, done, info = env.step(opt_action)\n",
    "        _, reward, terminated, _ , _ = env.step(opt_action)\n",
    "        num_action += 1\n",
    "        terminated = terminated.item()\n",
    "        day_reward += reward.item()\n",
    "\n",
    "    opt_reward[current_day] = day_reward\n",
    "\n",
    "    # Approaching end of current day\n",
    "    if terminated == True:\n",
    "        print(\"number of actions taken: {}\".format(num_action))\n",
    "        print(\"Simulation complete for total of {} days\".format(current_day))\n",
    "    current_day += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4b0c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1044.5566829738332, 2: 861.3592639213889, 3: 805.6513215031631, 4: 1007.3574626449497, 5: 887.7661076585582, 6: 927.1291526642696, 7: 1063.684094797056}\n",
      "{1: -1044.55668258667, 2: -861.3592681884766, 3: -805.6513214111328, 4: -1007.3574638366699, 5: -887.7660980224609, 6: -927.2235565185547, 7: -1063.684097290039}\n"
     ]
    }
   ],
   "source": [
    "print(optimization_day1_cost)\n",
    "print(opt_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
